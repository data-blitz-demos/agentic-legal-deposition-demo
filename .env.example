
OPENAI_API_KEY= <get one>

MODEL_NAME=gpt-5.2
OPENAI_MODELS=gpt-5.2
DEFAULT_LLM_PROVIDER=openai
# Docker Compose API container -> http://host.docker.internal:11434
# Local host API process      -> http://localhost:11434
OLLAMA_URL=http://host.docker.internal:11434
OLLAMA_DEFAULT_MODEL=initium/law_model:latest
OLLAMA_MODELS=initium/law_model:latest,initium/law_model:Q2_K
OLLAMA_KEEP_ALIVE=10m
LLM_READINESS_TTL_SECONDS=120
LLM_PROBE_TIMEOUT_SECONDS=12
LLM_OPTIONS_PROBE_WORKERS=3
COUCHDB_URL=http://admin:password@localhost:5984
COUCHDB_DB=depositions
MEMORY_DB=memory
THOUGHT_STREAM_DB=thought_stream
RAG_STREAM_DB=rag-stream
# Docker Compose API container -> bolt://neo4j:7687
# Local host API process      -> bolt://localhost:7687
NEO4J_URI=bolt://neo4j:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=password
NEO4J_DATABASE=neo4j
NEO4J_BROWSER_URL=http://localhost:7474/browser/
ONTOLOGY_DIR=./ontology
MAX_CONTEXT_DEPOSITIONS=20
DEPOSITION_DIR=./depositions
DEPOSITION_EXTRA_DIRS=
API_PORT=8000
COUCHDB_PORT=5984
NEO4J_HTTP_PORT=7474
NEO4J_BOLT_PORT=7687
